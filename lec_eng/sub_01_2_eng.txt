1.2.1
Let's start our first computer lesson. We launch R-Studio for the first time. And after starting R-Studio at the first launch we immediately find ourselves in the “console mode” (or in the “dialogue mode”) of operation. What is its peculiarity? Its peculiarity is that as soon as you have typed a command, it will be immediately executed. For example, I can use R as a simple calculator. This may not be the best use of R, but I can still type 5 plus 6 and get the answer: 11. I can do more complex calculations, too. For example, I can calculate the factorial of the number 10. But let's get back to more complex problems. Let's try to create a variable in which we will put the number 11. For example, let's create a variable b, in which we put the number 11. To do this, we will write b, and instead of “equal” we will use the following symbol: <- (less, arrow). And then the number 11, which we want to put in the variable b. And after we press Enter, the number 11 will fit into the variable b. Right here on the right in the corner we will see that: a list of variables with their values. Instead of an arrow in the form of a <- symbol, you can use = (equality symbol), but this assignment is considered not as stylish. That is, you can write d = 99, and this will also be correct, R will also understand such an assignment, but Google's style guide, for example, recommends using an assignment of two symbols. In particular, because such an assignment can be held in both directions: for example, you can write 5 -> a (put 5 on the other side of the variable a). So, the first thing to note when we create variables, – well, in addition to the fact that now you can work with them, for example, you can now type a + b and get, of course, the answer 16, because b contains the number 11, and the variable a contains the number 5, – it should be noted that there is a small nuance: R distinguishes between uppercase and lowercase letters. That is, if I create a variable A (uppercase), where I put 55, then “a” (lowercase) and “A” (uppercase) are two different variables. For example, I can write: a + A, and the result will be 60, because the lowercase “a” contains the number 5, and the uppercase “A” contains the number 55. You can create variables not from one letter, but long ones, which are maybe not so convenient to type, but they are more readable. That is, you can, for example, write: moe_lubimoe_chislo (“my favourite number” in Russian), and, say, put number 12 in this variable. And here we should immediately say that when you work with a function that has a long name, such as factorial, or here we have moe_lubimoe_chislo, there are a lot of symbols here, and it will take very long time to type. It makes sense to remember that there is such a useful button as tabulation. By pressing the Tab button, we can complete a long inscription if it has a single interpretation. For example, if I start writing moe_, since only the moe_lubimoe_chislo object begins with these four symbols (moe plus low line) in the computer memory, as soon as I press Tab now, I press only Tab button, and the computer will automatically add everything to the end. I can look at moe_lubimoe_chislo, it is still 12. Accordingly, it is the same with functions. If I type a function, like “facto”, I can press Tab and see all the functions that start with “facto”. Three functions begin with “facto” in R: factor, which creates categorical variables, factor.scope – to be honest, I don't even know what it is, – and factorial – calculates the factorial of a number. I press Escape because I don't need these functions right now. In addition to ordinary numbers, R easily works with large amounts of numbers, in particular with vectors. I can, for example, define a vector of numbers. Let’s create, for example, a vector w. No, let it be vector y. Vector y. It will be a vector of several numbers. Vectors and their descriptions begin with letter c. c, and then the necessary numbers are written in brackets and separated by commas. For example, it will be (3, -2, 5, 6, let me then write the mysterious number NA and then 9). c(3, -2, 5, 6, NA, 9). I can look at y, that is, I press y and Enter and now I see my vector: 3, -2, 5, 6, NA and 9. NA is an observation of a special type – a missed observation. In real data, unfortunately, there are often cases when respondents either refuse to answer the questionnaire, or for some other reason there is no data. Say, for a certain year you do not know what the GDP was, or there is a missing variable, then, accordingly, here NA means that you have no data. This is short for Not Available. And with the vector y, you can perform operations in the same way as with the number. Well, for example, I can write y + 2 and get the vector y increased by two. Naturally, where there were no observations, if you add 2 to NA, you get NA. But the computer will not give any error. Among the special objects, in addition to NA, there is also such an object as “not a number”. Well, for example, 0 divided by 0 is “not a number”. If I write 0/0, it is NaN (Not a Number). But nonetheless the computer does not give out an error, it just warns about the result of the operation. For example, I can put the result of dividing 0 by 0 into the variable t. (t <- 0/0: t arrow zero divided by zero). Well, here you can look at the variable t. t is not a number. And another special object that you have to work with is infinity. Sometimes, when applying the maximum likelihood method or some others, the result of the optimization procedure is some kind of an estimate equal to infinity. You shouldn't be intimidated by this. R can work correctly with an object such as infinity. For example, I can have one… Well, first of all, how can we get infinity? If 1 is divided by 0, then we get Infinity, here: Inf. Accordingly, if I divide 1 by Inf (note that Inf must be written with a capital letter, R distinguishes lowercase and uppercase letters), – if 1 is divided by Inf, it will be 0. If, for example, we take the arctangent of Infinity, atan(Inf), you get 1.57. Maybe someone will even recognize that 1.57 is pi over two. Let's compare. If I divide pi in half, I get 1.57. That is, the computer correctly takes the arctangent of infinity, and some other operations with infinity can also be performed. When a vector is created, it is usually read from real data, that is, you have a file somewhere that those people, who collected the questionnaires, filled out in some format, and you read it in R. But sometimes you have to create a vector by hand. As a rule, vectors of consecutive numbers are often needed. Well, for example, if I want to set a vector z of consecutive numbers from 100 to 200, then I will write 100, then ratio sign, then 200 (100:200), press Enter and now I can look at z. Here: z is my vector of numbers from 100 to 200. You can immediately say what the side numbers mean. The side numbers denote the number of the first element. Since z is a vector of 101 numbers (from one hundred to two hundred – one hundred and one number), that's why 118 is the 19th number, and 137 is the 38th number. Well, let's move on. If you made a mistake, for example, you typed coss(pi) – cosine with two “s” of pi – then the computer will respond with an error that it cannot find the cosine function. If you type the cosine correctly, not with two “s”, but with one, then there will be no problem. The cosine of pi is minus one. Another important thing that newbies often run into, and experienced users use, is that R allows you to enter one command in two lines. For example, if I got lost in my thoughts, started to enter the cosine of pi, but forgot to close the parenthesis and pressed Enter, then the computer realizes that the input was not finished. Either I wanted to add something inside the cosine of pi, or just close the parenthesis?.. You can see that the triangle sign (prompt) has changed to a plus sign. And since it has, it means that the computer is waiting for the continuation of the input. Well, if I paid attention to this, if this is an error there that I noticed, or it was done deliberately, then I can just finish typing, add a parenthesis, press Enter and get the same minus one. It is often used when you have a large expression, for example: five plus six plus seven minus nine, then you also decided to add something, pressed Enter, and again the prompt changed to a plus. Once again, this plus is not because I am adding, but because it is waiting for one more line, maybe two. It doesn’t mean that it is the last character of the line. It turned out like that coincidentally now. Well, respectively, plus ten plus seven. Wonderfully calculated: 26. But very often it happens with beginners: the appearance of this plus due to an error. You started to write: cos(pi), then added sin(, the parenthesis was not closed, a plus appeared. And you just understood, oh, I don’t want to continue this line. Well, then just press Escape, and the plus sign changes to a triangle, which says that you can enter the command again from scratch, and, accordingly, this is where our short introduction to the console will end, and then we will talk about the script writing mode, with which we have to work most of the time.

1.2.2
In the console mode in which we just worked, the command is executed immediately. I entered the command, pressed Enter, and it was executed. I entered the next command, pressed Enter, and it was executed. Of course, in real work the real data analysis is associated with the execution of a large number of commands, and therefore it makes sense to type them all in one file, and then run everything at once. And this second mode of operation is script writing. Let's move on to writing our first script. We press the “plus” sign here and then select R Script: we will get an additional window, and in this window, when we press Enter, nothing happens. The command will not be executed immediately. Let's create some vectors here. For example, let's create a vector x from numbers 23, 15, 46, NA and a vector z from numbers 5, 6, NA, 8. And let's try to execute these entered commands, since here the command is not executed immediately after writing. To execute a command, it is enough to “stand” anywhere in the line, you can go to the end, you can go to the beginning, but that’s not necessary. Where the cursor is located is the good place. And press a combination of buttons – depending on the operating system they will be different: for Windows users it will be Ctrl plus Enter, and on Mac it will be Command plus Enter. Accordingly, the first command was executed, x is vector of 23, 15, 46, missing value, and then we execute the second command: z is 5, 6, missing value, 8. What can I do with vectors? When working with vectors, I can try, for example, to calculate their average. If I type mean of x (“mean(x)”) and press Ctrl plus Enter, the computer will try to calculate the average value, the mean. But since there is a missed observation, it is impossible to find out the mean of these four numbers. R can deal well with missing observations: in this case I just need to indicate the option “omit missing values”, that is, I type the mean of x and indicate additional options that the missing values “​​na” should be omitted – “rm”. And it turns out that the mean, excluding the missing unknowns, is 28. Again, remember that Tab works, that is, I did not actually type na.rm. I typed, for example, “mean(z,)”, and then I pressed Tab and saw what options the function has, you can read them. Accordingly, here I selected the na.rm option, pressed Enter, set that it should be used, – TRUE (true value), and got the mean value of the z variable ignoring the missing values. In addition to the mean, you can calculate a bunch of other vector operations. For example, you can calculate the sum. Again, if you do not ignore the missing values, the amount is not known, however, you can ignore the missing values ​​and get the sum of all numbers except the missing ones. The next object that is very common in R in addition to vectors is a data frame. A data frame is a two-dimensional object, that is, there are several columns of the same length and – usually – many, many rows. Let's combine our vectors x and z into a frame d. For example, let x be the height of some aliens, and z – the weight of some four aliens. Let's create a table d: data.frame. Let's write that we take the height (rost) from the variable x, and we take the weight (ves) from the variable z. We pressed Ctrl plus Enter, and the computer combined two vectors x and z into a data frame d. Let's see how the table d works. Let's write d, then press Ctrl plus Enter. And so we see that d is a two-dimensional plate, there is a height variable and a weight variable. And observations. The first observation is height 23, weight 5. The second observation is height 15, weight 6 and so on. How do I address a two-dimensional object? Any specific element can be addressed. For example, if I want to get an element from the 4th row of the 1st column, then I need to write d[4, 1]. This will be the fourth row, first column. I press Ctrl plus Enter and it is indeed the missing value. For example, I can get an element from the third row of the first column: d[3, 1] is 46. I can get a whole row: for this you just need to skip the column number, so do not specify it: d[2, ], and without specifying the column number, I get the entire corresponding row. Similarly, without specifying the row number, you can get the entire column d[, 2] – this will be the second column. You can also address columns by name. For example, if I write d$rost… again: don't forget that Tab works. I started writing “d$ro” and hit Tab, and “st” appeared by itself. This, accordingly, will be the column rost from the plate d, and I can press Tab after $ in the same way and see what options there are. d$ves from the data frame d. In addition to data frames, lists are also very popular in R. It is convenient to think of the list as a closet with all sorts of rubbish. If a data frame has standard dimensions, – well, every data frame must have a certain number of rows, a certain number of columns, and each column has the same number of rows, – the list may include objects that are completely dissimilar. Well, let's try to create, for example, a list called my_list, which will include a number a = 7, a vector b of numbers from 10 to 20 and a data frame called “table”, where under the name table we will put our already created table d in the list my_list. Press Ctrl plus Enter: we have created an object my_list. my_list is a collection of three completely different objects. my_list$a is the number 7, my_list$b is a vector, my_list$table, – press Ctrl plus Enter – this is a whole data frame. Very often, the results of model estimation are presented in the form of a list, because, as a rule, when we estimate a model using the least squares method, the result of the evaluation is both a vector of estimates beta-hat and a number R-squared, so the results of evaluating many functions in R are just a list. A list is addressed slightly differently than a table. Well, firstly, the way of addressing by the name of the included object works, that is, when we added the height column to the table, then we could write d$rost and get the vector consisting of 4 numbers. The same way of addressing works with the list, and you can also address it by numbers. For example, I can write my_list, and in double square brackets I can specify the number of the object: for example, I have 3 objects here: a number, a vector and a table. Accordingly, if I write my_list and 2 in square brackets, then it will be the second object in the list. The second object in the list is vector b. You can use names or you can use numbers. When you've written a long, long script with a bunch of commands you need, you can happily write “Hooray!” and save your script for future reference. Choose File, Save. When you work with the Russian language, one of the first nuances that you will have to face is different encodings. Russian letters can be encoded in a file in different ways. The two most common methods (the most popular in Russia) are CP1251, which is common for Windows, and UTF-8, which is used for Mac and Linux. UTF-8 turns out to be more convenient, because this encoding allows using not only Russian, but, say, German umlauts, French accents, and so on in one file. Therefore, we will save in UTF-8 encoding and so here we will check the box that this UTF-8 encoding will be the default encoding for all files. However, if you see that you do not have Russian letters, but some kind of unclear hieroglyphs instead… well, for example, now my file is written in UTF-8 encoding. However, if I choose the wrong encoding and tell the computer that it is CP1251 encoding, then “hooray” will turn into unclear hieroglyphs. Therefore, if you see unclear hieroglyphs instead of comments, then select File, Reopen with Encoding and choose, most likely, one of the two encodings – either CP1251 or UTF-8. 

1.2.3
The good thing about R is that it's an open source, and that's why many different people have written a lot of different additional useful packages. And the real work usually starts with downloading a bunch of useful functions – packages – written by other people, and using them in your work. In order to use functions written by other people, you must first install some packages. Packages are installed through the Tools, Install Packages menu. If you find a package that is useful for you, then you download it like this. We need the following packages to get started. We are now installing them from the official repository, that is, this is such a large official storage, a site on the Internet called CRAN, and from there we install packages. dplyr for data processing, ggplot2 for pretty pictures, GGally for drawing scatterplot matrices, psych for descriptive statistics, and that’s it to begin with. But be prepared that we might need other packages, and they are installed in the same way: here you write their name separated by commas; you can, in principle, choose them from the list. And click Install. To install packages you require Internet connection, and after a while the packages will be installed. In addition to the official CRAN repository, where packages are installed through the “menu” like this, there is another large site called GitHub, and there users upload packages unofficially. This does not mean that they lack quality there. They can be just as useful, maybe users were just too lazy to put them on the official repository. How do we install packages from there? If you know the package author and package name, then you can install the package from the GitHub repository. This will require the devtools developer helper package. And after you've downloaded the devtools developer package, then you can install the packages from the GitHub repository. For this we will use the devtools package. Press Ctrl plus Enter and install the install_github package. That is, to install a package we need to know not only the name, but also on whose repository it is stored. On my repository I have uploaded a package for downloading statistical information from the HSE site sophisthse. Accordingly, bdemeshev/sophisthse is the name of the package. And we can install the package from the GitHub repository. Any real work starts with loading the packages you need using the library command. How do you know which packages you need? The easiest way is to find the information you need is google. That is, you type the command “How to solve differential”, – so, how to solve differential equations in R. You can look at the documentation and find that there is a deSolve package that allows you to solve differential equations in R. Accordingly, you can install the deSolve package and solve differential equations. And in our course we, of course, will tell you what packages we need and why. So, having installed the packages, they can be loaded into the computer's memory. library("dplyr") – this package allows you to manipulate data in a very convenient way. library("ggplot2") – this package allows you to draw beautiful graphs. library("GGally") allows you to draw many scatterplots at once. library("psych") allows descriptive statistics to be read very conveniently. How can I find help for a command? If you know which command you need, say, you have already figured out that you need the “predict” command to predict, then you can read the help on it: write “help(predict)”, press Ctrl plus Enter and get help on this command. There will be a description of the command with arguments, and at the end there will always be examples of use. Pay attention that here at the top is the name of the predict command and the package in which it is located in curly braces. Accordingly, if I, for example, type “help(describe)” – this is a command that describes a dataset: calculates the mean, minimum, maximum, and so on – then this command lies in the psych package. That is, in order to use the “describe” command, you must first install the “psych” package. If you do not know the name of the command you need, then the easiest way is to search the Internet, say, Google. And in addition to Google, you can use a special search engine in R called rseek.org. This is a search engine that will search specifically for pages that are somehow related to R. Accordingly, here I can type, say, rss, and see which R commands are generally related to the concept of the residual sum of squares. There are also two very helpful sites on the Internet: one site is stats.stackexchange.com, this is the place where statistical questions are asked. If you could not find the answer to your question on your own, which concerns data analysis, econometrics, statistics, the use of R or some algorithms for data analysis, then feel free to ask it here. You will most likely get help. And the second site: since data analysis is sometimes associated with purely programming difficulties, which seem to have nothing to do with the data analysis itself, but, nevertheless, they need to be solved, the stackoverflow.com site can help in solving programming issues. This is a huge place to ask questions related to programming. That is, if the first site stats.stackexchange.com is devoted specifically to statistical data analysis algorithms, then this one is purely devoted to programming issues. If you mark with a tag that your question is related to R and if you show that you made some effort to solve it, then you will definitely be helped. These are the online resources that will help you find help when dealing with R. And in R itself, you get help when you already know the name of the command. Type “help” and then the name of the command. For example, a command that estimates a model using the least squares method is called “lm”. And you can see possible options and examples of its use. You can also click on the “home” here and read Introduction to R or look for built-in documentation for all functions of specific keywords. 

1.2.4
Let's start our first data analysis. We create a new script. At the beginning of the script we’ll need four packages. You must install these packages yourself. We will need the following packages: firstly, the psych package, which is the package that allows us to use all sorts of descriptive statistics conveniently. We will use the dplyr package for data processing, we will use the ggplot2 package for pretty plots, and we will use the GGally package for the scatterplot matrix. Well, let's quickly go over right away, and press Ctrl plus Enter above each command. One, two, three, four. If – like in my case – the computer gave not a warning, but an error that the package is missing, then you need to install the package through Tools – Install Packages. There are many built-in datasets in R, let's take a look at the historical car dataset from the 1920s. We will take a table called cars, and for convenience, so as not to write cars all the time, we will put it in a variable, let it be d – this will be our data. Once again, “cars” is a dataset built into R. Let's take a look at it. Once you have a dataset, you, of course, need to look at it. Type “glimpse”, which means taking a look at the set d. So, here we see that in our table d there are two variables: speed and dist, – this is some kind of distance. Of course, you should know for yourself which meaning each variable in your dataset has, but since the cars dataset is built into R, you can call “help(cars)” command and see what every variable means there. And here we see what kind of a dataset it is: fifty observations, two variables, “speed” is the speed of the car in mph (miles per hour), and “dist” is the braking distance in feet. So, what else can you do with a dataset when you have it loaded? When you load some large dataset, it would be nice to check that everything was correctly transferred to R, that is, look at the beginning of the table using “head(d)”: these are the first six observations, and look at the end of the table using “tail(d)”. You can also view descriptive statistics using “describe(d)”. Accordingly, we see that we have a speed variable, the number of observations is 50, the mean is 15.40, the standard deviation is 5.29, the median is 15, and so on. And the braking distance has 50 observations, the mean value is 42 feet, the standard deviation is 25 feet, and so on. Minimum, maximum, difference between minimum and maximum, and so on. Likewise, you can see the number of observations separately, – sorry, I mean the number of columns, the number of variables “ncol(d)” (number of columns), – two columns; the number of rows, that is, the number of observations, (number of rows) “nrow(d)”, and it is also useful to look at the structure of the dataset d using “str(d)”. Accordingly, it will be said here that this is an object of type data.frame, fifty observations, two variables, the name of the variable, their type – each of them is numeric, – and the first few observations. It is possible to extract a separate vector from the dataset d and work with separate vectors. For example, if I want to calculate the average speed by myself, then I can type the mean of d, then the dollar sign and choose the speed variable. Then I press Ctrl plus Enter and get the average speed in the table d. When you have data, you usually need some kind of preprocessing of the data. We have the data presented, the speed is in miles per hour, and the length of the braking distance is in feet. For a Russian-speaking person, this is not very convenient, kilometers per hour and meters are more familiar, so we need to change the variables in order for us to understand it better, and for this the “mutate” command is used. The “mutate” command means to change the dataset, and then you need to specify the formulae by which the dataset is changed. That is, we will create a new table, let's call it d2. And to create this new table, we write mutate(d), that is, we change table d and create a new table d2, and the formulae by which we change the table will be as follows: speed equals to... if you look it up, say, in the Wikipedia, then you will find that one mile is about 1.6 kilometers, then, accordingly, to convert miles per hour to kilometers per hour, you need to multiply the old speed by 1.67. And you will also find that one foot is about 0.3 meters, so, to convert the length of the braking distance to meters, you must multiply the old length by 0.3. In the same way you can, for example, create a new variable, say, the ratio: how many times the braking distance differs from the speed. For example, I can create the ratio variable, which will equal the braking distance divided by the speed. Let me put this expression in several lines to make it clearer. And here you can see that I change the table d in accordance with the formulae and get a new table d2. Since this is a two-line command, then you either need to press Ctrl plus Enter two times, or select all and press once. I press Ctrl plus Enter, Ctrl plus Enter, I have the d2 table. You can look at the d2 table in the same way. And here, accordingly, there are three variables: speed, it is already in kilometers per hour, it is very convenient and familiar; here is the speed of a car in 1920, – 6.68 kilometers per hour or 13 kilometers per hour, simple and understandable; and the stopping distance is 3 meters, 4.8 meters. Before you start building regressions or esrimating more complex models, be sure to look at your data, build graphs. Graphs allow not only to avoid some major mistakes, but also to make serious scientific discoveries. Well, since our data set is not so rich – we have only two initial variables: car speed and braking distance, – then we will build two simple graphs. The first graph that we will build is a simple graph for figuring out the distribution law – a histogram. So, we will type a command “qplot” for plotting graphs, we will take the data from the d2 dataset, that is, we write data equals d2, because we have two datasets, d and d2, which are the same data, but in different units. d is feet and miles per hour and d2 is meters and kilometers per hour. We are now working with the d2 dataset. So, we need to build a histogram of the braking distance variable. We write the function, press Ctrl plus Enter and get a plot. According to the plot, we see that there is a very long braking distance, here, almost 40 meters, well, there is only one such car, because the number of cars is postponed along the vertical. But for most of them the length of the braking distance is centered around 10 meters. You should always be aware that there are two types of plots. You build one for yourself: quickly plotted, realized what was on the plot, visualized the data and went on to work; but there are plots that you build for publication, for presentation, and they need to be approached with a much greater investment of time. This plot is not good for publication, what is “dist”, what is “count”? Well, we know that “dist” is the braking distance, and “count” is the number of cars, but we need to add these parameters. That is, if we want the plot to be a good plot, then here we need to indicate the signature on the X axis: “xlab” equals…, and here we, accordingly, will name the length, the length of the braking distance (meters). In the same way we will add a label on the Y axis, you can make a command in several lines. Accordingly, the signature on the Y axis is the number of cars, and in the same way it is necessary to add the name of the plot, what kind of data it is, – so we will write “1920s data”, and this plot is much better already... There’s something I have not specified here… oh, I forgot that it is necessary to inline the “dist” variable. One, two, three. And this plot is clearer already. The criterion for the clarity of a plot is very simple: if you cut out the plot from a scientific article and it is clear what is depicted on it, then this is a good plot. If you have cut it out and you look at it and be like “oh, dist, what is it? Count, oh, what is this?” – this is not a good plot. A good plot is understandable when it is cut out of the paper. And now to the second plot that we can build for our dataset. This time we will build it quickly and for ourselves. We take the data from the d2 dataset, plot the vehicle speed horizontally and the braking distance – vertically, to understand how these variables are related. Press Ctrl plus Enter or Command plus Enter and we get such a natural dependence: the higher the speed of the car, the longer the braking distance. Further we will be able to move on to the estimation of the models. 

1.2.5
After we have looked at our plotted data, we can move on to estimating the models. In this case, since we understand the direction of the causal relationship – that the speed affects the length of the braking distance, – we will construct the dependence of the braking distance on speed, that is, we will estimate the linear regression model. This is done in R with one command, that is, we will write that our model is equal to lm, –  “lm” is a special command for the least squares method, “linear model”, – we will take the data from the dataset d2, and then we need to write the dependency formula. R or, more specifically, the “lm” command, has its own special format for describing models. The dependent variable is written first, that is, in this case the dependent variable is dist, the length of the braking distance, then the tilde (~) is written. The hardest part is finding the tilde on the keyboard. Once you have found the tilde on the keyboard, it is very easy to estimate the model. Here, put a tilde, and after that, separated by “plus” sign, you need to write all the explanatory variables, all the regressors. Well, since we have only one regressor – this is speed, – we simply write “speed” without adding anything else. Press Ctrl plus Enter, and that's it – our model has been estimated. Well, visually, there seems to be no reaction, but this is normal: the main thing is that there is a triangle, which says that there is no error and the model has been estimated. We can look at the results of the estimation, type “model” and press Ctrl plus Enter. And now we see the estimates of the coefficients. Estimation of the beta-one-hat (β1-hat) coefficient is minus five and beta-two-hat (β2-hat), the coefficient before speed, is 0.7. How will we interpret that? This means that, on average, with an increase in speed of one kilometer per hour, the braking distance increases by 0.7 meters. And this coefficient, although can be interpreted theoretically, would be expected to be around zero in our case, because what is it? This is the braking distance of the car, which is moving at zero speed, that is, this is the intercept, the intersection. And here we have a minus five. Well, this is what we got. So, what can we learn from the model? Once the computer has estimated the model, we can extract a bunch of indicators from it. Well, for example, we can extract the coefficients themselves into a separate vector. Let's call this vector beta_hat. beta_hat, respectively, is equal to the coefficients from our model, and this is convenient if I need any further actions on the coefficients, then I have them in a separate vector beta_hat. What else can you extract? You can extract the residuals epsilon-hat, eps_hat. These are the residuals. Don't forget that tab works. I wrote “residu”, pressed tab, and here are the options. We take out the residuals of the model and can now look at the vector eps_hat. This is a long vector of epsilon-hat, some epsilon-hat are positive, some are obviously negative. That is, somewhere the difference between the actual and predicted y is in one direction, somewhere in the other. Just in case, I will remind you that y itself, – let's put it for convenience in the vector y, – lives in the d2 table in the dist variable. In the d2 table our y lives in the dist variable, and y-predicted, y-hat, y_hat, can be extracted from the model using the “fitted” command. This is our model’s “fitted” vector, that is, you can look at our vector y, or you can look at the predicted vector y-hat. Apart from beta-hat, residuals epsilon-hat and y-hat, you can also extract the indicators RSS, ESS, TSS, R-squared and so on. There is a special command for RSS, which is called “deviance”: “deviance” of “model” is RSS. This designation is associated with a kind of generalization of the concept of RSS for other models. Unfortunately, there is no ready-made command for TSS, but, fortunately, it is not difficult to count it by hand. What is TSS? It is the sum of the squares of the deviation of y from the mean. Well, let's write that. If I write y minus mean of y (“mean(y)”), these are the deviations of y from the mean. If I square them, they will be the squares of the deviation from the mean, and if I sum them up (I put spaces on purpose to make the expression easier to read), then this will be the sum of the squares of the deviations from the mean. And this is what TSS is equal to. Well, of course, as we expected, TSS is bigger than RSS, and you can, for example, calculate the R-squared. Let me remind you that R-squared... Yes, ESS is, of course, TSS minus RSS. And you can calculate R-squared. R-squared is the ratio of the explained variance, that is, the ratio of the explained variance of ESS to TSS, and in our case R-squared is 0.65. There is also a second way to calculate the R-squared coefficient: you can take the sample correlation between the vector Y and the vector Y-hat, that is, the correlation between the actual values ​​of the braking distance and the predictions, and this will be the sample correlation. And if I square this sample correlation, then I get nothing but R-squared. That is, there are two ways to calculate the R-squared, and it is possible to do it using sample correlation. So, what else... The X matrix can also be extracted. Sometimes this is needed for some purpose, so let's extract it now from our model for educational purposes. There is such a concept as “model.matrix”. And, accordingly, here we can see how the big X matrix looked for our model. Well, if you look at it, write X, press Ctrl plus Enter, then this is actually a matrix with the size of the number of observations (fifty) and two columns. The first column consists of ones, the second column – of the speeds of the cars. After what we've learned from the model, we can, for example, use our model to predict. Let's create a new dataset for this, “nd”, a new dataset, this will be a data.frame, which has only the speed variable, and it will be equal to... Well, let's say I want to predict the braking distance for two cars that are moving – don’t forget we are talking about 1920s – 40 kilometers per hour and 60 kilometers per hour respectively. How much will they need to brake? I created a new dataset, let's look at it, press “nd”, then Enter. Here. It's just a dataset of one vector and two observations, 40 and 60. And now I can predict, using the “predict” command, and predict with the model I created, because the predictions from different models may differ. Accordingly, I use a model called “model for forecasting” and I take the data from the nd dataset. And it turns out that, well, with those characteristics, the first car would take 23 meters to brake, and the second car would take 37 meters to brake. And in addition to what we can predict for a new dataset according to the model, we can also visualize the estimation results, that is, draw the estimated line on the same plot where the scatterplot is located. Just copy the code of the old plot – qplot – here, data is equal to d2, horizontally we have speed, vertically – dist. Let's copy this code and use the fact that the ggplot2 package, in which the qplot function lives, allows us to draw graphs in layers, that is, we will write a “plus” and write what needs to be indicated on a new layer. On a new layer you need to specify a curve that replaces points, that is, in a sense, a smoothing curve, so this option is called “stat_smooth”, and specify the method by which this curve was obtained, the lm method. There are, of course, other methods as well. And, accordingly, we press Ctrl plus Enter and get the same graph, but our straight line is also plotted now, which, I will remind, has an equation… let’s see here: here is our model, minus 5 plus 0.7 times speed. Using this example, we learnt to estimate the simplest model using the least squares method, and extract the indicators of interest to us, such as: estimates of the coefficients, epsilon-hat, Y-hat, RSS, TSS, ESS, R-squared – even in two ways, – and matrix X; we also learnt to predict and visualize the results of the estimation on a plot. 

1.2.6
Consider another example of constructing a model and estimating it using the ordinary least squares. To do this, let's take another built-in dataset in R: the Swiss canton dataset. Let's put it in a table. Let's call the table “t” this time. Place the built-in swiss dataset in the t table. Again, you can read the documentation for this dataset and find that this is data from 1888, and the variables here are: Fertility is the number of children under five divided by the number of women, I think, under 50, and multiplied by 1000; Agriculture is the percentage of men employed in agriculture; Examination is some kind of the percentage of those who got a high result somewhere in the army exams, and so on. We have a description of this dataset. And we will try to see how fertility, that is, the number of children divided by the number of women, depends on the rest of the cantonal indicators. Again, never forget to look at the data, that is, I recommend looking at the table t at first. To do this, we'll use a command “glimpse(t)” to take a look at it. Here we see the variables and the first few values. You can see the descriptive statistics using “describe(t)”. Press Ctrl plus Enter, and we see the mean value for each variable, we see that we have 47 observations and so on. And, of course, look at the plots. Unfortunately, when you have a lot of quantitative variables, then the one scatterplot that we built is certainly not enough. In general, it is very difficult to visualize a complex dataset with a large number of variables. But one of the simplest ways to see or at least to somehow imagine a huge number of variables is to draw a large number of scatterplots. R has a ready-made function called “ggpairs”, which lives in the GGally package that we pre-loaded. So we can type “ggpairs(t)” and see the result. From the plots you can already understand that, for example, that Catholics do not like Protestants. And according to this graph, if I look at the variable proportion of the Catholic population in the canton, there is a sharp polarization: either 0% of the Catholic population, or 100%. Well, there are rare exceptions, but in general, if you look at the variable, you can see polarization: either 100% of the Catholic population, or 0%. That is, in this graph we have a scatter plot of each variable against each: the proportion of the Catholic population versus the Education variable, the proportion of men employed in agriculture versus the fertility variable. And here we can see some positive relationship: the higher the proportion of men employed in agriculture, the higher the fertility, that is, we can conclude that in rural regions, where more men are employed in agriculture, the birth rate is higher. Accordingly, here you can see some kind of negative relationship between fertility and the Examination variable. That is, this graph shows many dependencies, it can be studied for a long time. And we will move on to estimating the model using the ordinary least squares. Let's estimate a model – let it be model2 – using the least squares, that is, lm. According to the data from the table t, we estimate the following model: we will see what fertility depends on. That is, fertility is the dependent variable for us. We put a tilde (~) and here we write the explanatory variables. As potential explanatory factors let’s take, say, the proportion of men employed in agriculture, the education variable and the proportion of the Catholic population in the corresponding canton. So, we launch our command. The model is instantly estimated. We can look at the coefficients beta-hat in the estimated model. It can be seen that in our model, all other things being equal, the share of men employed in agriculture negatively affects fertility, education – also negatively, and the share of the Catholic population positively affects the fertility rate. You can again look at the predicted fertility values. The names of the Swiss cantons are signed here. You can see the residuals epsilon-hat of our model2. You can see the RSS indicator: deviance(model2)... I missed the letter n: deviance(model2). And you can calculate the R-squared. The R-squared can be calculated in another way. There is a ready-made report concept that calculates any additional statistics for the least squares method. Let's put a report on model2 into the “report” list. First of all, let’s take a look at this report. There is a lot of information here that we do not know yet, but, in particular, among other things, this report displays the indicator that we already know – the multiple R-squared of 0.64, and it can be extracted from this list using the dollar plus r.squared command ($r.squared). Accordingly, the R-squared in this model is 0.64, and it shows the correlation, the squared sample correlation between the predicted variable and the original explained variable. If I take the correlation from the table t, get the fertility variable and take the predicted values ​​from model2, this gives me the correlation between the predicted variable and the original dependent variable. And if I square that correlation, I get exactly the R-squared coefficient. Similarly, it is possible to predict in this dataset: if I take a new dataset nd2, data.frame, where I put hypothetical values ​​for some region, let's say, consider a region with a share of men employed in agriculture of 0.5, with a share the Catholic population also equal to 0.5, and with the education variable equal to 20. Let's create a new dataset. And now I will be able to predict for nd2 using model2. It turns out that the forecast for the rate of fertility, – that is, the number of children under five multiplied by 1000 and divided by the number of women, – is equal to 64.